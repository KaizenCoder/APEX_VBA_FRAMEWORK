import sqlite3
import os
import json
import re
import pandas as pd
from datetime import datetime
import argparse
import hashlib
import shutil
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns

# Constantes
VBA_KEYWORDS = ['vba', 'excel', 'access', 'sub', 'function', 'range', 'cells', 'workbook', 'worksheet', 'recordset', 'module', 'macro']
APEX_KEYWORDS = ['apex', 'framework', 'apex framework', 'test', 'ci', 'cd', 'pipeline']
ERROR_KEYWORDS = ['error', 'bug', 'fail', "doesn't work", 'ne fonctionne pas', 'erreur', 'debug', 'fix', 'probl√®me', 'issue']
TEST_KEYWORDS = ['test', 'testing', 'unit test', 'validation', 'ci', 'automated test']
CI_KEYWORDS = ['ci', 'cd', 'pipeline', 'build', 'deploy', 'integration', 'continuous', 'automation', 'workflow']

class CursorLogAnalyzer:
    """Analyseur des logs de conversation IA pour Apex Framework CI/CD."""
    
    def __init__(self, db_path=None, output_dir="reports", search_paths=None):
        self.db_path = db_path
        self.output_dir = output_dir
        self.prompts = []
        self.analysis_results = {}
        
        # Si aucun chemin de base de donn√©es n'est fourni, rechercher aux emplacements standard
        if not self.db_path:
            self.db_path = self.find_cursor_db(search_paths)
            
        # Cr√©er le r√©pertoire de sortie s'il n'existe pas
        os.makedirs(self.output_dir, exist_ok=True)
    
    def find_cursor_db(self, search_paths=None):
        """Trouver la base de donn√©es Cursor aux emplacements standard."""
        if not search_paths:
            search_paths = []
            
            # Ajout des emplacements standard
            appdata = os.getenv('APPDATA', '')
            if appdata:
                # Chercher dans tous les workspaces
                cursor_dir = os.path.join(appdata, 'Cursor', 'User', 'workspaceStorage')
                if os.path.exists(cursor_dir):
                    for workspace in os.listdir(cursor_dir):
                        workspace_path = os.path.join(cursor_dir, workspace)
                        if os.path.isdir(workspace_path):
                            db_path = os.path.join(workspace_path, 'state.vscdb')
                            if os.path.exists(db_path):
                                search_paths.append(db_path)
        
        # Si des chemins ont √©t√© trouv√©s, retourner le premier valide
        for path in search_paths:
            if os.path.exists(path):
                print(f"‚úÖ Base de donn√©es trouv√©e: {path}")
                return path
                
        print("‚ùå Aucune base de donn√©es Cursor trouv√©e!")
        return None
    
    def extract_prompts(self):
        """Extraire les prompts de la base de donn√©es SQLite."""
        if not self.db_path or not os.path.exists(self.db_path):
            print(f"‚ùå Base de donn√©es non trouv√©e: {self.db_path}")
            return False
            
        # Cr√©er une copie temporaire de la base pour √©viter les probl√®mes de verrouillage
        temp_db = os.path.join(self.output_dir, "temp_cursor_db.sqlite")
        try:
            shutil.copy2(self.db_path, temp_db)
            print(f"‚úÖ Copie temporaire cr√©√©e: {temp_db}")
        except Exception as e:
            print(f"‚ö†Ô∏è Impossible de cr√©er une copie temporaire: {e}")
            temp_db = self.db_path
            
        try:
            # Connexion en lecture seule
            uri = f"file:{temp_db}?mode=ro" if temp_db == self.db_path else f"file:{temp_db}"
            conn = sqlite3.connect(uri, uri=True)
            cursor = conn.cursor()
            
            # R√©cup√©rer les prompts depuis aiService.prompts
            print("üîç Extraction des prompts depuis aiService.prompts...")
            cursor.execute("SELECT value FROM ItemTable WHERE key = 'aiService.prompts';")
            row = cursor.fetchone()
            
            if not row:
                print("‚ùå Aucun prompt trouv√© dans aiService.prompts!")
                return False
                
            # D√©coder les donn√©es JSON
            if isinstance(row[0], bytes):
                value_str = row[0].decode('utf-8')
            else:
                value_str = str(row[0])
            
            prompts_data = json.loads(value_str)
            
            # V√©rifier que nous avons une liste de prompts
            if not isinstance(prompts_data, list):
                print(f"‚ùå Format inattendu dans aiService.prompts: {type(prompts_data)}")
                return False
                
            print(f"‚úÖ {len(prompts_data)} prompts trouv√©s.")
            
            # R√©cup√©rer les m√©tadonn√©es des g√©n√©rations
            cursor.execute("SELECT value FROM ItemTable WHERE key = 'aiService.generations';")
            gen_row = cursor.fetchone()
            
            generations = {}
            if gen_row:
                if isinstance(gen_row[0], bytes):
                    gen_str = gen_row[0].decode('utf-8')
                else:
                    gen_str = str(gen_row[0])
                
                gen_data = json.loads(gen_str)
                if isinstance(gen_data, list):
                    for gen in gen_data:
                        if 'generationUUID' in gen and 'unixMs' in gen:
                            generations[gen['generationUUID']] = {
                                'timestamp': gen['unixMs'],
                                'type': gen.get('type', 'unknown'),
                                'description': gen.get('textDescription', '')
                            }
            
            # Construire la liste des prompts avec contexte
            prompts = []
            
            for i, prompt in enumerate(prompts_data):
                if not isinstance(prompt, dict) or 'text' not in prompt:
                    continue
                    
                # Cr√©er l'objet de prompt
                prompt_obj = {
                    'text': prompt.get('text', ''),
                    'index': i,
                    'command_type': prompt.get('commandType', 'unknown'),
                    'uuid': prompt.get('generationUUID', ''),
                    'timestamp': None,
                    'timestamp_str': 'Inconnu',
                    'type': self.categorize_prompt(prompt.get('text', '')),
                    'has_ci_keywords': any(keyword in prompt.get('text', '').lower() for keyword in CI_KEYWORDS)
                }
                
                # Ajouter le timestamp si disponible
                if prompt_obj['uuid'] and prompt_obj['uuid'] in generations:
                    gen_info = generations[prompt_obj['uuid']]
                    prompt_obj['timestamp'] = gen_info['timestamp']
                    # Convertir le timestamp en cha√Æne lisible
                    if isinstance(prompt_obj['timestamp'], (int, float)):
                        dt = datetime.fromtimestamp(prompt_obj['timestamp']/1000)
                        prompt_obj['timestamp_str'] = dt.strftime('%Y-%m-%d %H:%M:%S')
                
                # D√©terminer le r√¥le (utilisateur ou IA)
                # Dans Cursor, commandType=4 semble √™tre utilis√© pour les messages
                prompt_obj['role'] = 'user' if prompt.get('commandType') == 4 else 'system'
                
                prompts.append(prompt_obj)
            
            self.prompts = prompts
            print(f"‚úÖ {len(prompts)} prompts trait√©s.")
            return True
            
        except sqlite3.Error as e:
            print(f"‚ùå Erreur SQLite: {e}")
            return False
        except json.JSONDecodeError as e:
            print(f"‚ùå Erreur d√©codage JSON: {e}")
            return False
        except Exception as e:
            print(f"‚ùå Erreur g√©n√©rale: {e}")
            return False
        finally:
            if 'conn' in locals():
                conn.close()
            
            # Supprimer la copie temporaire si elle existe
            if temp_db != self.db_path and os.path.exists(temp_db):
                try:
                    os.remove(temp_db)
                except:
                    pass
    
    def categorize_prompt(self, text):
        """Cat√©goriser le prompt en fonction de son contenu."""
        text_lower = text.lower()
        
        # D√©tection des types de prompts
        if any(keyword in text_lower for keyword in TEST_KEYWORDS):
            return 'test'
        elif any(keyword in text_lower for keyword in CI_KEYWORDS):
            return 'ci_cd'
        elif any(keyword in text_lower for keyword in ERROR_KEYWORDS):
            return 'debug'
        elif any(keyword in text_lower for keyword in VBA_KEYWORDS):
            return 'vba'
        elif any(keyword in text_lower for keyword in APEX_KEYWORDS):
            return 'apex'
        else:
            return 'other'
    
    def analyze_prompts(self):
        """Analyser les prompts pour extraire des informations utiles pour la CI."""
        if not self.prompts:
            print("‚ùå Aucun prompt √† analyser!")
            return False
            
        # Convertir en DataFrame pour faciliter l'analyse
        df = pd.DataFrame(self.prompts)
        
        # Trier par timestamp si disponible
        if 'timestamp' in df and df['timestamp'].notna().any():
            df = df.sort_values('timestamp', ascending=True)
        
        # 1. Analyser la distribution des types de prompts
        prompt_types = df['type'].value_counts().to_dict()
        
        # 2. D√©tecter les probl√®mes mentionn√©s (focus sur CI/CD)
        problems = []
        for _, row in df.iterrows():
            text = row['text'].lower()
            
            # V√©rifier si le prompt mentionne un probl√®me li√© √† CI/CD
            if any(keyword in text for keyword in ERROR_KEYWORDS) and (
               row['type'] in ['ci_cd', 'test'] or row['has_ci_keywords']):
                # Extraire un contexte autour du probl√®me
                for err_keyword in ERROR_KEYWORDS:
                    if err_keyword in text:
                        # Trouver la phrase contenant le mot-cl√© d'erreur
                        sentences = re.split(r'[.!?]', row['text'])
                        for sentence in sentences:
                            if err_keyword in sentence.lower():
                                # Ajouter le probl√®me avec contexte
                                problems.append({
                                    'text': sentence.strip(),
                                    'keyword': err_keyword,
                                    'timestamp': row['timestamp_str'],
                                    'type': row['type']
                                })
                                break
        
        # 3. Analyser la chronologie des interactions CI/CD
        ci_timeline = df[df['has_ci_keywords']].copy()
        if not ci_timeline.empty and 'timestamp' in ci_timeline and ci_timeline['timestamp'].notna().any():
            ci_timeline['date'] = pd.to_datetime(ci_timeline['timestamp'], unit='ms')
            ci_timeline = ci_timeline.set_index('date')
            ci_timeline = ci_timeline.sort_index()
        
        # 4. D√©tecter les tests et pipelines mentionn√©s
        tests_mentioned = []
        for _, row in df.iterrows():
            if row['type'] == 'test' or any(keyword in row['text'].lower() for keyword in TEST_KEYWORDS):
                # Extraire les mentions de tests
                test_matches = re.findall(r'test\s+([a-zA-Z0-9_]+)', row['text'], re.IGNORECASE)
                for match in test_matches:
                    tests_mentioned.append({
                        'name': match,
                        'context': row['text'][:100] + '...',
                        'timestamp': row['timestamp_str']
                    })
        
        # 5. Compter les mots-cl√©s CI/CD mentionn√©s
        ci_keywords_count = {keyword: 0 for keyword in CI_KEYWORDS}
        for _, row in df.iterrows():
            text = row['text'].lower()
            for keyword in CI_KEYWORDS:
                if keyword in text:
                    ci_keywords_count[keyword] += 1
        
        # Trier les mots-cl√©s par fr√©quence
        ci_keywords_count = dict(sorted(ci_keywords_count.items(), key=lambda x: x[1], reverse=True))
        
        # Stocker les r√©sultats
        self.analysis_results = {
            'prompt_types': prompt_types,
            'problems': problems,
            'ci_timeline': ci_timeline,
            'tests_mentioned': tests_mentioned,
            'ci_keywords_count': ci_keywords_count,
            'total_prompts': len(df),
            'ci_related_prompts': df['has_ci_keywords'].sum(),
            'prompts_df': df
        }
        
        print(f"‚úÖ Analyse termin√©e. {len(problems)} probl√®mes d√©tect√©s.")
        return True
    
    def generate_visualizations(self):
        """G√©n√©rer des visualisations pour l'analyse."""
        if not self.analysis_results:
            return False
            
        viz_dir = os.path.join(self.output_dir, 'ia_usage')
        os.makedirs(viz_dir, exist_ok=True)
        
        # 1. Distribution des types de prompts (pie chart)
        if self.analysis_results['prompt_types']:
            plt.figure(figsize=(10, 6))
            plt.pie(
                self.analysis_results['prompt_types'].values(), 
                labels=self.analysis_results['prompt_types'].keys(),
                autopct='%1.1f%%',
                startangle=90
            )
            plt.title('Distribution des Types de Prompts')
            plt.axis('equal')
            plt.tight_layout()
            plt.savefig(os.path.join(viz_dir, 'prompt_types_distribution.png'))
            plt.close()
        
        # 2. Chronologie des interactions CI/CD
        if not self.analysis_results['ci_timeline'].empty and 'type' in self.analysis_results['ci_timeline'].columns:
            # Compter par jour et type
            try:
                daily_counts = self.analysis_results['ci_timeline'].resample('D')['type'].value_counts().unstack().fillna(0)
                plt.figure(figsize=(12, 6))
                daily_counts.plot(kind='bar', stacked=True)
                plt.title('Interactions CI/CD par Jour')
                plt.xlabel('Date')
                plt.ylabel('Nombre de Prompts')
                plt.tight_layout()
                plt.savefig(os.path.join(viz_dir, 'ci_interactions_timeline.png'))
                plt.close()
            except:
                pass
        
        # 3. Mots-cl√©s CI/CD les plus fr√©quents
        plt.figure(figsize=(10, 6))
        keywords = list(self.analysis_results['ci_keywords_count'].keys())
        counts = list(self.analysis_results['ci_keywords_count'].values())
        # Filtrer les mots-cl√©s avec des occurrences
        keywords = [k for i, k in enumerate(keywords) if counts[i] > 0]
        counts = [c for c in counts if c > 0]
        
        if keywords and counts:
            plt.bar(keywords, counts)
            plt.title('Mots-cl√©s CI/CD les Plus Fr√©quents')
            plt.xlabel('Mot-cl√©')
            plt.ylabel('Nombre d\'occurrences')
            plt.xticks(rotation=45, ha='right')
            plt.tight_layout()
            plt.savefig(os.path.join(viz_dir, 'ci_keywords_frequency.png'))
            plt.close()
        
        return True
    
    def generate_ci_report(self, format='markdown'):
        """G√©n√©rer un rapport d'analyse orient√© CI."""
        if not self.analysis_results:
            print("‚ùå Aucun r√©sultat d'analyse √† inclure dans le rapport!")
            return False
            
        if format.lower() == 'markdown':
            return self.generate_markdown_report()
        elif format.lower() == 'html':
            return self.generate_html_report()
        else:
            print(f"‚ö†Ô∏è Format non support√©: {format}")
            return self.generate_markdown_report()
    
    def generate_markdown_report(self):
        """G√©n√©rer un rapport en format Markdown."""
        report_file = os.path.join(self.output_dir, 'ia_usage_report.md')
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(f"""# Rapport d'Analyse des Logs IA pour CI/CD Apex Framework

## R√©sum√©

* **Total de prompts analys√©s:** {self.analysis_results['total_prompts']}
* **Prompts li√©s √† CI/CD:** {self.analysis_results['ci_related_prompts']} ({self.analysis_results['ci_related_prompts']/self.analysis_results['total_prompts']*100:.1f}%)
* **Probl√®mes d√©tect√©s:** {len(self.analysis_results['problems'])}
* **Tests mentionn√©s:** {len(self.analysis_results['tests_mentioned'])}

## Distribution des Types de Prompts

""")
                # Distribution des types
                for prompt_type, count in self.analysis_results['prompt_types'].items():
                    percentage = count / self.analysis_results['total_prompts'] * 100
                    f.write(f"* **{prompt_type}:** {count} ({percentage:.1f}%)\n")
                
                f.write("""
## Probl√®mes CI/CD D√©tect√©s

Les probl√®mes suivants ont √©t√© identifi√©s dans les conversations li√©es √† CI/CD:

""")
                # Probl√®mes d√©tect√©s
                if self.analysis_results['problems']:
                    for i, problem in enumerate(self.analysis_results['problems'], 1):
                        f.write(f"{i}. **Probl√®me ({problem['timestamp']}, Type: {problem['type']})**: \"{problem['text']}\"\n")
                else:
                    f.write("Aucun probl√®me sp√©cifique √† CI/CD n'a √©t√© d√©tect√©.\n")
                
                f.write("""
## Tests Mentionn√©s

Les tests suivants ont √©t√© mentionn√©s dans les conversations:

""")
                # Tests mentionn√©s
                if self.analysis_results['tests_mentioned']:
                    for i, test in enumerate(self.analysis_results['tests_mentioned'], 1):
                        f.write(f"{i}. **{test['name']}** ({test['timestamp']}): \"{test['context']}\"\n")
                else:
                    f.write("Aucun test sp√©cifique n'a √©t√© mentionn√© explicitement.\n")
                
                f.write("""
## Mots-cl√©s CI/CD les Plus Fr√©quents

""")
                # Mots-cl√©s CI/CD
                for keyword, count in self.analysis_results['ci_keywords_count'].items():
                    if count > 0:
                        f.write(f"* **{keyword}**: {count} mentions\n")
                
                f.write("""
## Suggestions pour l'Am√©lioration de CI/CD

Bas√© sur l'analyse des conversations, les am√©liorations suivantes sont recommand√©es:

""")
                # G√©n√©rer des suggestions bas√©es sur les probl√®mes
                suggestions = self.generate_ci_suggestions()
                if suggestions:
                    for i, suggestion in enumerate(suggestions, 1):
                        f.write(f"{i}. {suggestion}\n")
                else:
                    f.write("Aucune suggestion automatique n'a pu √™tre g√©n√©r√©e √† partir des donn√©es disponibles.\n")
                
                f.write("""
## Conclusion

Ce rapport a √©t√© g√©n√©r√© automatiquement √† partir de l'analyse des logs d'IA pour soutenir le d√©veloppement CI/CD d'Apex Framework.

""")
                
                # Ajouter des liens vers les visualisations
                viz_dir = os.path.join('ia_usage')
                f.write("""
## Visualisations

""")
                for viz_file in ['prompt_types_distribution.png', 'ci_interactions_timeline.png', 'ci_keywords_frequency.png']:
                    file_path = os.path.join(viz_dir, viz_file)
                    if os.path.exists(os.path.join(self.output_dir, file_path)):
                        f.write(f"![{viz_file}]({file_path})\n\n")
            
            print(f"‚úÖ Rapport g√©n√©r√©: {report_file}")
            return True
                
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration du rapport: {e}")
            return False
    
    def generate_html_report(self):
        """G√©n√©rer un rapport en format HTML."""
        # Simplification: utiliser pandas pour g√©n√©rer un rapport HTML basique
        report_file = os.path.join(self.output_dir, 'ia_usage_report.html')
        
        try:
            # Cr√©er un HTML de base
            html_content = f"""<!DOCTYPE html>
<html>
<head>
    <title>Rapport d'Analyse IA pour CI/CD</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        h1, h2, h3 {{ color: #333; }}
        .container {{ max-width: 1200px; margin: 0 auto; }}
        .chart {{ margin: 20px 0; }}
        table {{ border-collapse: collapse; width: 100%; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; }}
        th {{ background-color: #f2f2f2; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>Rapport d'Analyse des Logs IA pour CI/CD Apex Framework</h1>
        
        <h2>R√©sum√©</h2>
        <ul>
            <li><strong>Total de prompts analys√©s:</strong> {self.analysis_results['total_prompts']}</li>
            <li><strong>Prompts li√©s √† CI/CD:</strong> {self.analysis_results['ci_related_prompts']} ({self.analysis_results['ci_related_prompts']/self.analysis_results['total_prompts']*100:.1f}%)</li>
            <li><strong>Probl√®mes d√©tect√©s:</strong> {len(self.analysis_results['problems'])}</li>
            <li><strong>Tests mentionn√©s:</strong> {len(self.analysis_results['tests_mentioned'])}</li>
        </ul>
        
        <h2>Visualisations</h2>
"""
            
            # Ajouter des liens vers les visualisations
            viz_dir = 'ia_usage'
            for viz_file in ['prompt_types_distribution.png', 'ci_interactions_timeline.png', 'ci_keywords_frequency.png']:
                file_path = os.path.join(viz_dir, viz_file)
                if os.path.exists(os.path.join(self.output_dir, file_path)):
                    html_content += f"""
        <div class="chart">
            <h3>{viz_file.replace('_', ' ').replace('.png', '').title()}</h3>
            <img src="{file_path}" alt="{viz_file}" style="max-width: 100%;">
        </div>
"""
            
            # Ajouter des tableaux pour les probl√®mes et tests
            if self.analysis_results['problems']:
                html_content += """
        <h2>Probl√®mes CI/CD D√©tect√©s</h2>
        <table>
            <tr>
                <th>#</th>
                <th>Timestamp</th>
                <th>Type</th>
                <th>Description</th>
            </tr>
"""
                for i, problem in enumerate(self.analysis_results['problems'], 1):
                    html_content += f"""
            <tr>
                <td>{i}</td>
                <td>{problem['timestamp']}</td>
                <td>{problem['type']}</td>
                <td>{problem['text']}</td>
            </tr>"""
                
                html_content += """
        </table>
"""
            
            # Fermer le HTML
            html_content += """
    </div>
</body>
</html>
"""
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(html_content)
                
            print(f"‚úÖ Rapport HTML g√©n√©r√©: {report_file}")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration du rapport HTML: {e}")
            return False
    
    def generate_ci_suggestions(self):
        """G√©n√©rer des suggestions pour l'am√©lioration de CI/CD bas√©es sur l'analyse."""
        if not self.analysis_results:
            return []
            
        suggestions = []
        
        # 1. Suggestions bas√©es sur les probl√®mes d√©tect√©s
        if self.analysis_results['problems']:
            # Regrouper les probl√®mes par type
            problems_by_type = {}
            for problem in self.analysis_results['problems']:
                problem_type = problem['type']
                if problem_type not in problems_by_type:
                    problems_by_type[problem_type] = []
                problems_by_type[problem_type].append(problem)
            
            # G√©n√©rer des suggestions sp√©cifiques par type
            if 'ci_cd' in problems_by_type and len(problems_by_type['ci_cd']) > 0:
                suggestions.append("Am√©liorer les scripts de pipeline CI/CD pour r√©soudre les probl√®mes r√©currents.")
                
            if 'test' in problems_by_type and len(problems_by_type['test']) > 0:
                suggestions.append("Renforcer la suite de tests automatis√©s pour couvrir les cas probl√©matiques identifi√©s.")
        
        # 2. Suggestions bas√©es sur l'utilisation
        if self.analysis_results['ci_related_prompts'] / self.analysis_results['total_prompts'] < 0.1:
            suggestions.append("Augmenter l'utilisation de CI/CD dans le processus de d√©veloppement (moins de 10% actuellement).")
        
        # 3. Suggestions bas√©es sur les tests
        if not self.analysis_results['tests_mentioned']:
            suggestions.append("Impl√©menter une strat√©gie de test automatis√© int√©gr√©e √† la CI/CD.")
        elif len(self.analysis_results['tests_mentioned']) < 5:
            suggestions.append("√âtendre la couverture des tests automatis√©s pour couvrir plus de fonctionnalit√©s.")
        
        # Ajouter des suggestions g√©n√©riques si n√©cessaire
        if len(suggestions) < 3:
            suggestions.extend([
                "Mettre en place une validation automatique des prompts IA dans les pipelines de d√©veloppement.",
                "Impl√©menter des m√©triques de qualit√© pour √©valuer les interactions avec l'IA.",
                "Consid√©rer l'int√©gration d'une √©tape d'analyse des logs IA dans le pipeline CI/CD."
            ])
        
        return suggestions[:5]  # Limiter √† 5 suggestions

def main():
    parser = argparse.ArgumentParser(description='Analyser les logs de conversation IA pour CI/CD.')
    parser.add_argument('--db-path', help='Chemin vers la base de donn√©es SQLite de Cursor.')
    parser.add_argument('--output-dir', default='reports', help='R√©pertoire de sortie pour les rapports.')
    parser.add_argument('--format', choices=['markdown', 'html'], default='markdown', help='Format du rapport g√©n√©r√©.')
    args = parser.parse_args()
    
    # Initialiser l'analyseur
    analyzer = CursorLogAnalyzer(db_path=args.db_path, output_dir=args.output_dir)
    
    # Extraire et analyser les prompts
    if analyzer.extract_prompts():
        if analyzer.analyze_prompts():
            # G√©n√©rer des visualisations
            analyzer.generate_visualizations()
            
            # G√©n√©rer le rapport
            if analyzer.generate_ci_report(format=args.format):
                print(f"‚úÖ Analyse termin√©e avec succ√®s! Rapport g√©n√©r√© dans le r√©pertoire: {args.output_dir}")
                return 0
    
    print("‚ùå L'analyse a √©chou√©.")
    return 1

if __name__ == "__main__":
    exit(main()) 